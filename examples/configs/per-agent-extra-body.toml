# ── Per-Agent Extra Body Config ────────────────────────────────────
# Shows how extra_body works with per-agent LLM overrides.
# Each agent's LLM config can have its own extra_body parameters.
#
# Use case: different reasoning effort levels per stage — light for
# extraction (extract/map/learn), heavy for synthesis (create).

[llm]
provider = "openai-compatible"
model = "meta/llama-3.1-70b-instruct"
api_key_env = "GATEWAY_API_KEY"
base_url = "https://api.your-gateway.com/v1"

[llm.extra_body.reasoning]
effort = "low"

[generation]
max_retries = 5
max_source_tokens = 100000
# Disable parallel extraction if your gateway has tight rate limits
# parallel_extraction = false

# Create stage uses higher reasoning effort for synthesis
[generation.create_llm]
provider = "openai-compatible"
model = "meta/llama-3.1-70b-instruct"
api_key_env = "GATEWAY_API_KEY"
base_url = "https://api.your-gateway.com/v1"

[generation.create_llm.extra_body.reasoning]
effort = "high"

# Test stage uses OpenAI for code validation
[generation.test_llm]
provider = "openai"
model = "gpt-5.2"
api_key_env = "OPENAI_API_KEY"
