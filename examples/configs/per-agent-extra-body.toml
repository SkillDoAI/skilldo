# ── Per-Agent Extra Body Config ────────────────────────────────────
# Shows how extra_body works with per-agent LLM overrides.
# Each agent's LLM config can have its own extra_body parameters.
#
# Use case: different reasoning effort levels per agent — light for
# extraction (agents 1-3), heavy for synthesis (agent 4).

[llm]
provider = "openai-compatible"
model = "meta/llama-3.1-70b-instruct"
api_key_env = "GATEWAY_API_KEY"
base_url = "https://api.your-gateway.com/v1"

[llm.extra_body.reasoning]
effort = "low"

[generation]
max_retries = 5
max_source_tokens = 100000
# Disable parallel extraction if your gateway has tight rate limits
# parallel_extraction = false

# Agent 4 uses higher reasoning effort for synthesis
[generation.agent4_llm]
provider = "openai-compatible"
model = "meta/llama-3.1-70b-instruct"
api_key_env = "GATEWAY_API_KEY"
base_url = "https://api.your-gateway.com/v1"

[generation.agent4_llm.extra_body.reasoning]
effort = "high"

# Agent 5 uses OpenAI for code validation
[generation.agent5_llm]
provider = "openai"
model = "gpt-5.2"
api_key_env = "OPENAI_API_KEY"
